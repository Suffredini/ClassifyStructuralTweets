package classifier;

import java.io.IOException;
import java.text.DecimalFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import utility.ClassifierData;
import weka.core.converters.ConverterUtils;
import utility.IOManager;
import static utility.IOManager.writeToCsvFile;
import weka.attributeSelection.InfoGainAttributeEval;
import weka.attributeSelection.Ranker;
import weka.classifiers.Classifier;
import weka.classifiers.Evaluation;
import weka.classifiers.bayes.NaiveBayesMultinomial;
import weka.classifiers.functions.LibSVM;
import weka.classifiers.lazy.IBk;
import weka.classifiers.meta.AdaBoostM1;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.trees.J48;
import weka.classifiers.trees.RandomForest;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stopwords.StopwordsHandler;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.Filter;
import weka.filters.MultiFilter;
import weka.filters.supervised.attribute.AttributeSelection;
import weka.filters.supervised.instance.SMOTE;
import weka.filters.supervised.instance.SpreadSubsample;
import weka.filters.supervised.instance.StratifiedRemoveFolds;
import weka.filters.unsupervised.attribute.NominalToString;
import weka.filters.unsupervised.attribute.StringToWordVector;


public class BuildClassifierSameTweetsPerClassAndKeywords {
    /* START Parameter */
    private static final String rowTweetsCSV = "file/tweetsKeywords.csv";// Format: tweet;class;keyword
    private static final String stopWordFile = "file/stopWord";    
    
    private static int selectedClassifier = 1;  /*  (0) DecisionTree 
                                                    (1) SVM 
                                                    (2) MultinomialNB 
                                                    (3) kNN 
                                                    (4) Adaboost 
                                                    (5) RandomForest
                                                */
    private static final int numberFolds = 10;
    private static final int numberSeed = 2;
    
    private static double percValue = 100.0; // oversampling percentage (fatti vari esperimenti e con 130 si ha maggior fscore per svm)
    private static int mValue = 1; // ratio undersampling mValue:1 (fatti vari esperimenti e con 5 si ha maggior fscore per svm)
    
    private static int kValue = 1; // k of k-nn 
    
    private static double weightC0 = 0.3; // weight of class C0, weight for class C1 autogenerated (fatti vari esperimenti e con 0.3 si ha maggior fscore per svm)
    private static final int cValue = 1; // c of SVM 
    
    private static boolean selectNumberOfFeatures = false; // If true set the number of feature selected at nFeatures
    private static int nFeatures = 50;    
    
    private static boolean printAllClassifiers = false; // Print or not CM and other metrics of each classifier
    /* END Parameter */
    
    /* Keyword utilizzate per scaricare i tweet che andranno classificati nel tool finale */
    private static final String[] keyWord = 
    {
        "allagamento","allagata","allagato","allerta meteo","alluvionato",
        "alluvione", "caditoia", "caditoie", "condotta", "condotte", "condotto",
        "diluviando", "diluviare", "diluvio", "fogna", "fognaria", "fognatura",
        "fogne", "maltempo", "pioggia", "piove", "scarica", "scarichi", "scarico",
        "scola", "scoli", "scolo", "sommerge", "sommergere", "sommersa", "sommerse",
        "tombini", "tombino", "tubatura", "tubature", "tubazione"
            
    };  

    
    private static Instances trainSet, testSet, data, datasetFinalCheck;
    private static int numberTweets;
    private static String[] tweets; 
    private static String[] classes;
    private static String[] keywords;    
    private static double[] accuracyFold;
    private static double[] fscoreFold;
    private static double[] precisionFold;
    private static double[] recallFold;
    private static String[] matrixFold;
    private static Evaluation[] evalFold;
    private static FilteredClassifier[] classifierFold;
    private static String classifierName = "";
    private static Map<String, Integer> confusionMatrix;
    
    private static double maxFscore;
    private static String selectedParameter;
    private static double[] maxAccuracyFold;
    private static double[] maxFScoreFold;
    private static double[] maxPrecisionFold;
    private static double[] maxRecallFold;
    private static Map<String, Integer> maxCMFold; 

    
    public static void main(String[] args) throws IOException, Exception {
        System.out.println("Classifier [START]");
        maxAccuracyFold = new double[numberFolds*numberSeed];
        maxFScoreFold = new double[numberFolds*numberSeed];
        maxPrecisionFold = new double[numberFolds*numberSeed];
        maxRecallFold = new double[numberFolds*numberSeed];
        
        // Importo i tweet, diverso da quello nell'altro main, seleziona anche tanto Non Structural quanti Structural per parola          
        importTweets(rowTweetsCSV);
        double selectedw0 = 0.5;
        int selectedK = 1;
        // Commentare o decoimmentare i for a seconda dell'esperimento, settare anche stampa dentro if a fine ciclo
        //for(int k=1; k<=5; k+=1){               
            //kValue = k;
        //for(double w=0.3; w<=0.7; w+=0.1){               
            //weightC0 = w;
        
            accuracyFold = new double[numberFolds*numberSeed];
            fscoreFold = new double[numberFolds*numberSeed];
            precisionFold = new double[numberFolds*numberSeed];
            recallFold = new double[numberFolds*numberSeed];
            matrixFold = new String[numberFolds*numberSeed];
            evalFold = new Evaluation[numberFolds*numberSeed];
            classifierFold = new FilteredClassifier[numberFolds*numberSeed];
            confusionMatrix = new HashMap<>();
            confusionMatrix.put("TP", 0);
            confusionMatrix.put("FP", 0);
            confusionMatrix.put("FN", 0);
            confusionMatrix.put("TN", 0);          
            
            int sizeArray;

            // Ripeto per le 10 fold dalvandomi i risultati ad ogni istanza
            for(int seed=0; seed<numberSeed; seed++){
                for(int fold=0; fold<numberFolds; fold++){            
                    // Ottengo test set e training set
                    splitDataset(fold+1,seed);
                    textClassification(fold*numberSeed+seed);
                }
            } 

            if(maxFscore < average(fscoreFold)){  
                String printParameter = "";
                switch(selectedClassifier){                
                    case 1:                
                        printParameter = "W_non-structural:" + weightC0;
                        selectedK = kValue;
                        break;

                    case 3:                
                        printParameter = "k: " + kValue;
                        selectedw0 = weightC0;
                        break;          
                } 
                System.out.println("[Best Fscore] -> " + printParameter);
               
                selectedParameter = printParameter;
                maxFscore = average(fscoreFold);
                sizeArray = numberFolds*numberSeed;
                System.arraycopy(accuracyFold, 0, maxAccuracyFold, 0, sizeArray);
                System.arraycopy(fscoreFold, 0, maxFScoreFold , 0, sizeArray);
                System.arraycopy(precisionFold, 0, maxPrecisionFold, 0, sizeArray);
                System.arraycopy(recallFold, 0, maxRecallFold, 0, sizeArray);
                maxCMFold = new HashMap<>(confusionMatrix); 
            }
        //}
        
        //Ripristino i valori del miglior risultato ottenuto cos√¨ che vengano stampati 
        accuracyFold = maxAccuracyFold;
        fscoreFold = maxFScoreFold;
        precisionFold = maxPrecisionFold;
        recallFold = maxRecallFold;
        confusionMatrix = maxCMFold;        
          
        System.out.println("\nClassificator: " + classifierName);
        printResultIndex();
        //}
        
        
        // Costruisco un calssificatore usando tutti i dati, poi lo testo con i tweets esclusi
        System.out.println("\nEvaluation with remaning tweets:");
        
        //ripristino il miglior parametro individuato
        switch(selectedClassifier){                
            case 1:                
                weightC0 = selectedw0;
                break;

            case 3:                
                kValue = selectedK;
                break;          
        } 
        
        FilteredClassifier classifier = buildClassifier(data);                     
                
        Evaluation evalExcluded = new Evaluation(data);
        evalExcluded.evaluateModel(classifier, datasetFinalCheck);
        printIndex(evalExcluded);
        
        exportClassifier(classifier,classifierName+"(Exp.2)");
        //printAndSerializeBestClassifier();
        System.out.println("Classifier [END]");
    }
    
    private static Instances doOversampling(Instances train, int seed) throws Exception{
        SMOTE smtFilter = new SMOTE();
        smtFilter.setPercentage(percValue);
        smtFilter.setNearestNeighbors(5);
        smtFilter.setRandomSeed(seed);
	smtFilter.setInputFormat(train);
        return Filter.useFilter(train, smtFilter);
    }
    
          
    private static Instances doUndersampling(Instances inst, int seed) throws Exception {
        SpreadSubsample ff = new SpreadSubsample();
        String opt = "-M "+mValue+" -X 0.0 -S "+seed;
        String[] optArray = weka.core.Utils.splitOptions(opt);
        ff.setOptions(optArray);
        ff.setInputFormat(inst);        
        return Filter.useFilter(inst, ff);
    }
    
    
    private static void importTweets(String path) throws Exception {
        // Il file path √® stato preparato manualmente mediante excel
        List<String[]> classList = IOManager.readFromCsvFile(";",path);
 
        numberTweets = classList.size();
        tweets = new String[numberTweets];
        classes = new String[numberTweets];
        keywords = new String[numberTweets];
        
        int tweetNumber = 0;
        //Concatenate the 5 bit of class
        for(String[] s : classList){
            tweets[tweetNumber] = s[0]; 
            classes[tweetNumber] = s[1];            
            keywords[tweetNumber] = s[2];
            tweetNumber++;
        } 
        
        tweets = deleteUrlAndPic(tweets);

        List<String[]> out = new ArrayList<>();
        String[] tmp = new String[3];
        
        tmp[0] = "tweetTweet";
        tmp[1] = "classTweet";
        tmp[2] = "keywordTweet";
        out.add(tmp);
        
        for(int pos = 0; pos<numberTweets; pos++){
            tmp = new String[3];
            tmp[0] = tweets[pos];
            tmp[1] = classes[pos];
            tmp[2] = keywords[pos];
            out.add(tmp);
        }        
        writeToCsvFile(out,",","tmp.csv");
        // Read all the instances in the file (ARFF, CSV, XRFF, ...)
        ConverterUtils.DataSource source = new ConverterUtils.DataSource("tmp.csv");
        data = source.getDataSet();
        
        // Converto il tipo dei tweets da nominal a string cosi da poter applicare StringToWordVector
        String[] nsOptions = {"-C", "1"};
        NominalToString nsFilter = new NominalToString();
        nsFilter.setInputFormat(data);
        nsFilter.setOptions(nsOptions);
        data = Filter.useFilter(data, nsFilter);
        
        Instances dataset = new Instances(data,0);
        dataset.deleteAttributeAt(dataset.numAttributes() - 1);
       // data.setClassIndex(data.numAttributes() - 1); // Questo √® attributo key
        Instances keywordInstances;
        datasetFinalCheck = new Instances(data);
        for(String word: keyWord){
            int index = data.attribute(data.numAttributes() - 1).index();
 
            keywordInstances = new Instances(data, 0); // Empty Instances with same header

            //Estraggo tutte le parole con una certa keyword  da data
            data.parallelStream()
                    .filter(instance -> instance.stringValue(index).equals(word))
                    .forEachOrdered(keywordInstances::add);
            
            // Se una classe non ha elementi struttuirali la salto altrimenti alla fine andrebbro nel dataset tutti i tweet con classe 0
            if(keywordInstances.attributeStats(1).nominalCounts[1] < 1){
                continue;
            }
            keywordInstances.deleteAttributeAt(keywordInstances.numAttributes() - 1);            
            keywordInstances.setClassIndex(keywordInstances.numAttributes() - 1); //Questo √® attributo class
                        
            keywordInstances = doUndersampling(keywordInstances,1);
                     
            for(int inst = 0; inst < keywordInstances.numInstances(); inst++){
                dataset.add(keywordInstances.get(inst));
                // Preparo il dataset contenente gli esclisi per la verifica finale
                for(int i=0; i<datasetFinalCheck.numInstances(); i++){
                    if(datasetFinalCheck.get(i).stringValue(0).equals(keywordInstances.get(inst).stringValue(0))){
                       datasetFinalCheck.delete(i);
                       break;
                    }                    
                }
            }
        }
        
        data = dataset;
        data.setClassIndex(data.numAttributes() - 1);        
        datasetFinalCheck.deleteAttributeAt( datasetFinalCheck.numAttributes() - 1);
        datasetFinalCheck.setClassIndex(datasetFinalCheck.numAttributes() - 1);
        System.out.println("Dataset for final verification: \n"+datasetFinalCheck.attributeStats(datasetFinalCheck.numAttributes() - 1));
        System.out.println("Dataset for build classifier: \n"+data.attributeStats(data.numAttributes() - 1));
    }
    
    private static void splitDataset(int fold, int seed) throws Exception {
        // Estraggo train set
        StratifiedRemoveFolds strRmvFoldsTrain = new StratifiedRemoveFolds();
        String optionsSRFTrain = ( "-S "+seed+" -N "+numberFolds+" -F "+fold+" -V");
        String[] optionsArrayTrain = optionsSRFTrain.split( " " );
        strRmvFoldsTrain.setOptions(optionsArrayTrain);
        strRmvFoldsTrain.setInputFormat(data);
        trainSet = StratifiedRemoveFolds.useFilter(data, strRmvFoldsTrain);

        // Estraggo test set
        StratifiedRemoveFolds strRmvFoldsTest = new StratifiedRemoveFolds();
        String optionsSRFTest = ( "-S "+seed+" -N "+numberFolds+" -F "+fold);
        String[] optionsArrayTest = optionsSRFTest.split( " " );
        strRmvFoldsTest.setOptions(optionsArrayTest);
        strRmvFoldsTest.setInputFormat(data);
        testSet = StratifiedRemoveFolds.useFilter(data, strRmvFoldsTest);
    }

    private static StringToWordVector getTextElaborationFilter() throws Exception {
        MyStopwordsHandler msh = new MyStopwordsHandler(stopWordFile);
        
        StringToWordVector filter = new StringToWordVector();
        filter.setAttributeIndices("1");
        filter.setTokenizer(new WordTokenizer());
        filter.setWordsToKeep(100000); // Massimo numero di feat. da mantenere
        filter.setLowerCaseTokens(true);
        filter.setDoNotOperateOnPerClassBasis(true);
        filter.setIDFTransform(true); //Inverse document frequency
        filter.setTFTransform(true);  // Tiene conto della frequenza del termine nella parola        
        
        // Aggiungo le Stopwords
        filter.setStopwordsHandler(msh); //external stop words file

        // Aggiungo lo Stemmer          
        SnowballStemmer stemmer = new SnowballStemmer();
        stemmer.setStemmer("italian");
        filter.setStemmer(stemmer);
        
        return filter;
    }
    
    private static  AttributeSelection getAttributeSelectionFilter() throws Exception {
        Ranker ranker = new Ranker();
        ranker.setThreshold(0);	// IG threshold
        
        if(selectNumberOfFeatures){
            ranker.setNumToSelect(nFeatures);
        }
        
        AttributeSelection as= new AttributeSelection();
        as.setEvaluator(new InfoGainAttributeEval());
        as.setSearch(ranker);
        return as;
    }
    
    private static FilteredClassifier buildClassifier(Instances dataset) throws Exception{
        FilteredClassifier classifier = new FilteredClassifier();
        MultiFilter mf = new MultiFilter();
        Filter[] filters = new Filter[2];
        filters[0] = getTextElaborationFilter();
        //filters[1] = getOversamplingFilter();
        filters[1] = (Filter) getAttributeSelectionFilter();
        mf.setFilters(filters);

        classifier.setFilter(mf);
        
        Classifier classifierSelected = null;

        switch(selectedClassifier){
            case 0:                
                classifierSelected = doDecisionTree();
                classifierName = "DecisionTree";
                break;
                
            case 1:                
                classifierSelected = doSVM();
                classifierName = "SVM";
                break;
                
            case 2:                
                classifierSelected = doMultinomialNB();
                classifierName = "MultinomialNB";
                break;
                
            case 3:                
                classifierSelected = dokNN();
                classifierName = "kNN";
                break;
                
            case 4:                
                classifierSelected = doAdaboost();
                classifierName = "Adaboost";
                break;
                
            case 5:                
                classifierSelected = doRandomForest();
                classifierName = "RandomForest";
                break;
                
            default:
                // Non √® stato selezionato un classificatore o ne √® stato sbagliato il nome
                System.out.println("[ERROR] Wrong classificator selected, check paramiter");
                System.exit(1);            
        } 
        
        classifier.setClassifier(classifierSelected);
        classifier.buildClassifier(dataset);
        return classifier;
    }
    
        
    private static void textClassification(int index) throws Exception { 
        FilteredClassifier classifier = buildClassifier(trainSet);                      
        Evaluation eval = new Evaluation(trainSet);        
        eval.evaluateModel(classifier, testSet);
        saveFoldResult(index, eval, classifier); 
        
        if(printAllClassifiers){
            System.out.println("\nIndex: " + index);        
            printIndex(eval);
        }
    }
    
    private static double getAccuracy(Evaluation eval){
        double tp = eval.numTruePositives(1);
        double tn = eval.numTrueNegatives(1); 
        double fp = eval.numFalsePositives(1);
        double fn = eval.numFalseNegatives(1); 
        if(tp+tn == 0.0){
            return 0.0;
        } 
        return ((tp+tn)/(tp+tn+fp+fn))*100;
    }
    
    private static double getPrecision(Evaluation eval){
        double tp = eval.numTruePositives(1);
        double fp = eval.numFalsePositives(1); 
        if(tp == 0.0){
            return 0.0;
        }
        return (tp/(tp+fp))*100;
    }
    
    private static double getRecall(Evaluation eval){
        double tp = eval.numTruePositives(1);
        double fn = eval.numFalseNegatives(1); 
        if(tp == 0.0){
            return 0.0;
        }
        return (tp/(tp+fn))*100;
    }
        
    private static double getFscore(Evaluation eval){
        double precision = getPrecision(eval);
        double recall = getRecall(eval);
        if(precision == 0.0 || recall == 0.0){
            return 0.0;
        }
        return 2 * ((precision*recall)/(precision + recall)); // beta = 1
    }
 
    private static void printIndex(Evaluation eval) throws Exception{
        DecimalFormat df = new DecimalFormat("#.##");
        int tp = (int) eval.numTruePositives(1);
        int tn = (int) eval.numTrueNegatives(1); 
        int fp = (int) eval.numFalsePositives(1);
        int fn = (int) eval.numFalseNegatives(1);
        String indexValue =     "\t| Accuracy: " + df.format(getAccuracy(eval)) +
                                "\n" +
                                "\t| F-Score: " + df.format(getFscore(eval)) +
                                "\n" +
                                "\t| Precision: " + df.format(getPrecision(eval)) +
                                "\n" +
                                "\t| Recall: " + df.format(getRecall(eval)) +
                                "\n";

        System.out.println(indexValue);

        System.out.println("\t    Structural \t Non Structural");
        System.out.println("Structural \t " + tp + " \t " + fn);
        System.out.println("Non Structural \t " + fp + " \t " + tn);
        
    }
  
    private static Classifier doDecisionTree() throws Exception {        
        String [] options =new String[1];
        options[0] = "-U";
        J48 classificator = new J48();
        classificator.setOptions(options);        
        return (Classifier) classificator;
    }
    
    private static Classifier doSVM() throws Exception {
        LibSVM classificator= new LibSVM();
         // Mettendo i pesi -W costruendo la stringa a partire dai double non li prende...
        String[] optionsArray = {"-S", "0", "-K", "0", "-C", ""+cValue, "-E", "0.001", "-W", "0.4 0.6"};
        classificator.setOptions( optionsArray );
        return (Classifier) classificator;
    }
    
    private static Classifier doMultinomialNB() throws Exception {
        NaiveBayesMultinomial classificator = new NaiveBayesMultinomial();
        return (Classifier) classificator;
    }
    
    private static Classifier dokNN() throws Exception {        
        IBk classificator = new IBk();
        String options = "-K "+kValue;
        String[] optionsArray = options.split( " " );
        classificator.setOptions( optionsArray );
        return (Classifier) classificator;
    }
    
    private static Classifier doAdaboost() throws Exception {
        AdaBoostM1 classificator = new AdaBoostM1();
        return (Classifier) classificator;
    }
    
    private static Classifier doRandomForest() throws Exception {
        RandomForest classificator = new RandomForest();
        return (Classifier) classificator;
    }

        
    private static String[] deleteUrlAndPic(String[] tweets){
        String urlRegex = "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+";
        String picRegex = "pic.twitter.com/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+";
        String hashtagRegex = "\\B#\\w*[a-zA-Z]+\\w*";
        String mentionsRegex = "(?:@[\\w_]+)";        
   
        for(int i = 0; i<tweets.length; i++){
            // "\\p{P}" rimuove tutta la punteggiatura, "( )+" rimpiazza spazzi bianchi multipli con uno solo 
            tweets[i] = tweets[i].replaceAll(urlRegex, "").replaceAll(picRegex, "").replaceAll(hashtagRegex, "")
                            .replaceAll(mentionsRegex, "").replaceAll("\\p{P}", " ").replaceAll("( )+"," ").toLowerCase();
        }  
        return tweets;
    }
    
    private static void exportClassifier(FilteredClassifier c, String name) throws IOException, Exception{
        ClassifierData cd = new ClassifierData();
        cd.classifierName = name;
        cd.classifier = c;
        // Keyword utilizate delezionate dai parametri ad inizio classe
        cd.researchKey = keyWord; 
        //weka.core.SerializationHelper.write("classifier/"+name+".classifier", c); // Nemmeno con questo lo esporta
        IOManager.saveClassBinary("classifier/"+name+".classifier", cd);
    }

    private static void saveFoldResult(int index, Evaluation eval, FilteredClassifier classifier) throws Exception {
        accuracyFold[index] = getAccuracy(eval);
        fscoreFold[index] = getFscore(eval);
        precisionFold[index] =  getPrecision(eval);
        recallFold[index] = getRecall(eval);
        matrixFold[index] =  eval.toMatrixString();     
        evalFold[index] = eval;
        classifierFold[index] = classifier;
        
        int tp = (int) eval.numTruePositives(1);
        int tn = (int) eval.numTrueNegatives(1); 
        int fp = (int) eval.numFalsePositives(1);
        int fn = (int) eval.numFalseNegatives(1); 
        
        
        int oldTP = confusionMatrix.get("TP");
        int oldFP = confusionMatrix.get("FP");
        int oldFN = confusionMatrix.get("FN");
        int oldTN = confusionMatrix.get("TN");
        
        confusionMatrix.replace("TP",oldTP,oldTP+tp);
        confusionMatrix.replace("FP",oldFP,oldFP+fp);
        confusionMatrix.replace("FN",oldFN,oldFN+fn);
        confusionMatrix.replace("TN",oldTN,oldTN+tn);
    }
    
    private static String printStringVector(double[] values) {
        DecimalFormat df = new DecimalFormat("#.##");
        String ret = "[  ";
        for(double val : values){
            ret += df.format(val) + "  "; 
        }
        return ret + "]";
    }
    
    private static double average(double[] n) {
        double sum = 0;
        for(double value:n){
            sum+=value;
        }
        return sum/n.length;
    }
    
    private static String confidanceInterval(double[] values) {
        double average = average(values);
        double varianceSum = 0.0;
        for (int i = 0; i < values.length; i++) {
            varianceSum += (values[i] - average) * (values[i] - average);
        }
        double variance = varianceSum / (values.length - 1);
        double standardDaviation = Math.sqrt(variance);
        DecimalFormat df = new DecimalFormat("#.##");
        return df.format(average) + " +- " + df.format(1.96 * (standardDaviation/Math.sqrt(values.length))); // 2.58
    }

    private static void printResultIndex() {
        System.out.println(selectedParameter+"\n");
        System.out.println("Accuracy: \n\t" + confidanceInterval(accuracyFold)+ " \t "  + printStringVector(accuracyFold));
        System.out.println("F-Score: \n\t" + confidanceInterval(fscoreFold)+ " \t"  + printStringVector(fscoreFold));
        System.out.println("Precision: \n\t" + confidanceInterval(precisionFold)+ " \t"  + printStringVector(precisionFold));
        System.out.println("Recall: \n\t" + confidanceInterval(recallFold)+ " \t"  + printStringVector(recallFold));

        System.out.println("\t    Structural \t Non Structural");
        System.out.println("Structural \t " + confusionMatrix.get("TP") + " \t " + confusionMatrix.get("FN"));
        System.out.println("Non Structural \t " + confusionMatrix.get("FP") + " \t " + confusionMatrix.get("TN"));
        System.out.println("\n");
    }
    
    private static int getBestIndex(double[] values){
        int index = 0;
        double maxTmp = 0.0;
        for(int pos=0; pos<values.length; pos++){
            if(values[pos] > maxTmp){
                maxTmp = values[pos];
                index = pos;
            }
        }
        return index;
    }

    private static void printAndSerializeBestClassifier() throws Exception {
        System.out.println("Classifier with best F-Score: ");
        int bestFScoreClassifierIndex = getBestIndex(fscoreFold);
        printIndex(evalFold[bestFScoreClassifierIndex]);
        exportClassifier(classifierFold[bestFScoreClassifierIndex], classifierName);
    }



}